# optimizer
epochs: 90
batch_size: 64
test_batch_size: 64
weight_decay: 0.0002
lr: 0.1
momentum: 0.9
lr_decline:
  - 83
  - 86
# pgd
train_num_steps: 5
train_step_size: 0.0078
train_epsilon: 0.031
test_num_steps: 20
test_step_size: 0.0078
test_epsilon: 0.031
random: True

# loss functions
beta: 6.0

# log and save model
log_interval: 100
save_freq: 1
eval_freq: 1
log_level: 'INFO'

# dataset
imbalance_ratio: 0.02
dataset: CIFAR10
num_classes: 10

# train opts
train_mode: pgd_at
loss_opt: ~
sampler: ClassAware
backbone: WideResNet
classifier: PostNorm
classifier_opt:
  tau: 1
  norm: False
  avg_T: 1
  bias: False
  lws: True
model_dir: ./checkpoints/cifar10-0.02-pgd-5-LWS
lr_dict:
  cla_scale: 0.1
  else: 0.0

remark: ~
resume_epoch: 80
load_model: ./checkpoints/cifar10-0.02-pgd-5/epoch80.pt
# test
model_path: ./checkpoints/cifar10-0.02-pgd-5-LWS/epoch81.pt


