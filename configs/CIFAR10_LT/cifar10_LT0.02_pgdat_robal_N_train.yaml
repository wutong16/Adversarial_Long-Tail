# optimizer
epochs: 80
batch_size: 64
test_batch_size: 64
weight_decay: 0.0002
lr: 0.1
momentum: 0.9
lr_decline:
  - 60
  - 75

# pgd
train_num_steps: 5
train_step_size: 0.0078
train_epsilon: 0.031
test_num_steps: 20
test_step_size: 0.0078
test_epsilon: 0.031
random: True


# log and save model
log_interval: 100
save_freq: 10

# dataset
imbalance_ratio: 0.02
dataset: CIFAR10
num_classes: 10

# train paths
train_mode:
  add_reg:
    beta_adv: 1.0
    beta_nat: 0.0
    beta_reg: 6.
    reg_opt: trades
loss_opt:
  MultiMargin:
    m: 0.1
    s: 10
    tau_b: 1.2
    tau_m: 0

adv_loss_opt: ~
nat_loss_opt: ~

sampler: ~
backbone: WideResNet
classifier: CosPlus
classifier_opt:
  bias: False
  gamma: 0.03125
  scale: 1
  mu: 0.9

model_dir: ./checkpoints/cifar10-0.02-pgd-5-cos-s10m0.1-tau_m0b1.2
resume_epoch: 0

# test
model_path: ./checkpoints/cifar10-0.02-pgd-5-cos-s10m0.1-tau_m0b1.2/epoch80.pt


