# optimizer
epochs: 80
batch_size: 64
test_batch_size: 64
weight_decay: 0.0002
lr: 0.1
momentum: 0.9
lr_decline:
  - 60
  - 75

# pgd
train_num_steps: 5
train_step_size: 0.0078
train_epsilon: 0.031
test_num_steps: 20
test_step_size: 0.0078
test_epsilon: 0.031
random: True


# log and save model
log_interval: 100
save_freq: 10

# dataset
imbalance_ratio: 0.02
dataset: CIFAR10
num_classes: 10

# train paths
train_mode: pgd_at
loss_opt: ~
sampler: ~
backbone: WideResNet
classifier: PostProc
classifier_opt:
  bias: False
  tau_p: 1
  posthoc: True
  classifier: FC

model_dir: ./checkpoints/cifar10-0.02-pgd-5-post-LA/
resume_epoch: 0
remark: LA-tau1
# test
model_path: ./checkpoints/cifar10-0.02-pgd-5/epoch80.pt


