# optimizer
epochs: 80
batch_size: 64
test_batch_size: 64
weight_decay: 0.0002
lr: 0.1
momentum: 0.9
lr_decline:
  - 60
  - 75

# pgd
train_num_steps: 5
train_step_size: 0.0078
train_epsilon: 0.031
test_num_steps: 20
test_step_size: 0.0078
test_epsilon: 0.031
random: True


# log and save model
log_interval: 100
save_freq: 10

# dataset
imbalance_ratio: 0.1
dataset: CIFAR100
num_classes: 100

# train paths
train_mode:
  add_reg:
    beta_adv: 1.0
    beta_nat: 0.
    beta_reg: 3.
    reg_opt: trades

loss_opt:
  MultiMargin:
    m: 0.2
    s: 10
    tau_m: 0
    tau_b: 0
adv_loss_opt: ~
nat_loss_opt: ~

sampler: ~
backbone: WideResNet
classifier: CosPlus
classifier_opt:
  bias: False
  gamma: 0.03125
  scale: 1
model_dir: ./checkpoints/cifar100-0.1-pgd-5-cos-s10m0.2-tau_m0b0/
resume_epoch: 0

# test
model_path: ./checkpoints/cifar100-0.1-pgd-5-cos-s10m0.2-tau_m0b0/epoch80.pt

